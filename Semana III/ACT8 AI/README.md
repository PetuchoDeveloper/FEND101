# ACT8 AI - Suite de Pruebas Async para Cliente EcoMarket

## üìã Descripci√≥n

Este proyecto implementa una **suite completa de 20 tests** usando `pytest + pytest-asyncio + aioresponses` para validar el cliente HTTP as√≠ncrono de EcoMarket. Los tests cubren 4 categor√≠as cr√≠ticas:

1. **Equivalencia Funcional** (5 tests)
2. **Concurrencia Correcta** (5 tests)
3. **Timeouts y Cancelaci√≥n** (5 tests)
4. **Edge Cases de Concurrencia** (5 tests)

## üìÅ Estructura del Proyecto

```
ACT8 AI/
‚îú‚îÄ‚îÄ README.md                      # Este archivo
‚îú‚îÄ‚îÄ test_cliente_async.py          # Suite principal (20 tests)
‚îú‚îÄ‚îÄ conftest.py                    # Fixtures compartidos
‚îú‚îÄ‚îÄ pytest.ini                     # Configuraci√≥n de pytest
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias
‚îú‚îÄ‚îÄ cliente_ecomarket_async.py     # M√≥dulo a testear (copiado de ACT3)
‚îú‚îÄ‚îÄ validadores.py                 # Validaci√≥n de esquemas (copiado de ACT7)
‚îú‚îÄ‚îÄ url_builder.py                 # Constructor de URLs seguras (copiado de ACT3)
‚îî‚îÄ‚îÄ reporte_bugs.md                # Reporte de bugs encontrados (generado despu√©s de tests)
```

## üöÄ Instalaci√≥n

```bash
cd "Semana III/ACT8 AI"
pip install -r requirements.txt
```

**Dependencias necesarias:**
- pytest==8.0.0
- pytest-asyncio==0.23.5
- aiohttp==3.9.3
- aioresponses==0.7.6

## üß™ Ejecuci√≥n de Tests

### Ejecutar Suite Completa

```bash
pytest -v test_cliente_async.py
```

### Ejecutar por Categor√≠a

```bash
# Solo tests de equivalencia funcional
pytest -v -m funcional

# Solo tests de concurrencia
pytest -v -m concurrencia

# Solo tests de timeout/cancelaci√≥n
pytest -v -m timeout

# Solo edge cases
pytest -v -m edge_case
```

### Ejecutar Test Espec√≠fico

```bash
pytest -v test_cliente_async.py::test_gather_tres_peticiones_exitosas
```

### Generar Reporte de Coverage

```bash
pytest --cov=cliente_ecomarket_async --cov-report=html test_cliente_async.py
```

El reporte HTML se generar√° en `htmlcov/index.html`.

## üìä Categor√≠as de Tests

### 1Ô∏è‚É£ Equivalencia Funcional (5 tests)

Verifican que las funciones as√≠ncronas retornan exactamente lo mismo que las s√≠ncronas.

- `test_listar_productos_async_vs_sync`: Estructura de respuesta id√©ntica
- `test_validacion_datos_productos`: Validaci√≥n de esquema funciona igual
- `test_manejo_errores_http_401_403_500`: Errores HTTP se manejan igual
- `test_timeout_individual_respetado`: Timeout configurable por funci√≥n
- `test_respuesta_malformada_json`: JSON inv√°lido lanza excepci√≥n apropiada

### 2Ô∏è‚É£ Concurrencia Correcta (5 tests)

Prueban que `gather()`, sem√°foros y coordinaci√≥n funcionan correctamente.

- `test_gather_tres_peticiones_exitosas`: 3 peticiones paralelas completan
- `test_gather_un_fallo_con_return_exceptions`: Manejo tolerante de errores
- `test_gather_sin_return_exceptions_propaga_error`: Modo estricto propaga errores
- `test_cargar_dashboard_un_fallo_de_cuatro`: Dashboard parcial funciona
- `test_semaforo_limita_concurrencia`: L√≠mite de concurrencia respetado

### 3Ô∏è‚É£ Timeouts y Cancelaci√≥n (5 tests)

Validan que timeouts individuales y cancelaci√≥n en cadena funcionan correctamente.

- `test_timeout_individual_cancela_solo_peticion_lenta`: Timeout aislado
- `test_error_401_cancela_peticiones_en_cadena`: Cancelaci√≥n en cadena por auth
- `test_timeout_global_dashboard_respetado`: Timeout global del dashboard
- `test_cancelled_error_no_deja_sesiones_abiertas`: Cleanup de recursos
- `test_peticion_cancelada_no_genera_log_errors`: Logs apropiados

### 4Ô∏è‚É£ Edge Cases de Concurrencia (5 tests)

Situaciones extremas y errores compuestos.

- `test_todas_peticiones_fallan_simultaneamente`: Todos los endpoints fallan
- `test_servidor_cierra_conexion_mitad_respuesta`: Connection reset
- `test_respuesta_llega_despues_del_timeout`: Respuesta tard√≠a ignorada
- `test_dos_peticiones_mismo_endpoint`: Par√°metros diferentes
- `test_sesion_cierra_correctamente_despues_gather_con_errores`: Cleanup con errores

## üêõ Proceso de Testing y Bug Reporting

1. **Ejecutar tests**: `pytest -v test_cliente_async.py`
2. **Identificar fallos**: Revisar output de pytest
3. **Documentar en `reporte_bugs.md`**: Cada bug con reproducci√≥n y descripci√≥n
4. **Aplicar correcciones**: Modificar `cliente_ecomarket_async.py`
5. **Re-ejecutar tests**: Validar que los fixes funcionan
6. **Actualizar reporte**: Agregar secci√≥n "Correcci√≥n Aplicada"

## üìà M√©tricas Esperadas

- **Coverage esperado**: > 85% del c√≥digo del cliente async
- **Tests exitosos**: 20/20 si el c√≥digo es correcto
- **Tiempo de ejecuci√≥n**: < 5 segundos (con mocks)

## üí° Ejemplos de Uso

### Ver Resultado de un Test

```bash
pytest -v test_cliente_async.py::test_gather_tres_peticiones_exitosas -s
```

### Ejecutar Solo Tests que Fallaron

```bash
pytest --lf  # last-failed
```

### Modo Verbose con Output Capturado

```bash
pytest -vv -s test_cliente_async.py
```

## üîç Interpretaci√≥n de Resultados

- ‚úÖ **PASSED**: Test exitoso, comportamiento correcto
- ‚ùå **FAILED**: Bug detectado, revisar traceback
- ‚ö†Ô∏è **XFAIL**: Fallo esperado (si se marc√≥ con `@pytest.mark.xfail`)
- ‚è≠Ô∏è **SKIPPED**: Test omitido (si se marc√≥ con `@pytest.mark.skip`)

## üìö Referencias

- [pytest documentation](https://docs.pytest.org/)
- [pytest-asyncio](https://pytest-asyncio.readthedocs.io/)
- [aioresponses](https://github.com/pnuckowski/aioresponses)
- [aiohttp testing](https://docs.aiohttp.org/en/stable/testing.html)

---

**Autor**: Antigravity AI (QA Specialist)  
**Fecha**: 12 de febrero de 2026  
**Versi√≥n**: 1.0
