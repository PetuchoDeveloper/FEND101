# Sistema de Control de TrÃ¡fico HTTP - ACT5 AI

## ğŸ¯ Objetivo

Implementar un sistema robusto de **limitaciÃ³n de concurrencia** y **rate limiting** para el cliente HTTP asÃ­ncrono de EcoMarket, diseÃ±ado como un ingeniero de control de trÃ¡fico profesional.

## ğŸš¨ El Problema

Cuando `crear_multiples_productos()` lanza 100 peticiones POST simultÃ¡neas, puede causar:

1. **Sobrecarga del Servidor**: El servidor tiene lÃ­mite de 20 conexiones concurrentes
2. **Agotamiento de File Descriptors**: El cliente puede quedarse sin file handles
3. **ViolaciÃ³n de Rate Limits**: El API tiene mÃ¡ximo de 30 peticiones por segundo
4. **Conexiones fallidas**: Timeouts y errores por saturaciÃ³n

### Ejemplo del Problema

```python
# âŒ Sin control de trÃ¡fico
async def crear_100_productos():
    tareas = [crear_producto(p) for p in productos]  
    # Â¡100 peticiones simultÃ¡neas! ğŸ’¥
    return await asyncio.gather(*tareas)
```

**Resultado**: Servidor saturado, errores de conexiÃ³n, peticiones rechazadas.

## âœ… La SoluciÃ³n

Sistema de throttling con **tres componentes reutilizables**:

### 1. **ConcurrencyLimiter** (usando `asyncio.Semaphore`)

Limita el nÃºmero de peticiones **simultÃ¡neas**:

```python
limiter = ConcurrencyLimiter(max_concurrent=10)

async with limiter.acquire():
    # MÃ¡ximo 10 peticiones aquÃ­ simultÃ¡neamente
    response = await session.get(url)
```

**CaracterÃ­sticas**:
- âœ… Context manager: `async with limiter.acquire()`
- âœ… Logging de peticiones en vuelo
- âœ… Thread-safe usando `asyncio.Lock`

### 2. **RateLimiter** (algoritmo Token Bucket)

Limita el **rate de peticiones por segundo**:

```python
limiter = RateLimiter(max_per_second=20)

async with limiter.acquire():
    # MÃ¡ximo 20 peticiones por segundo
    response = await session.get(url)
```

**Algoritmo Token Bucket**:
1. Bucket tiene capacidad mÃ¡xima de tokens (ej: 20)
2. Se regeneran tokens a rate constante (20/segundo)
3. Cada peticiÃ³n consume 1 token
4. Si no hay tokens disponibles, la peticiÃ³n **espera** (no se rechaza)

**Ventajas**:
- âœ… Maneja bursts controlados
- âœ… Las peticiones esperan en cola, no fallan
- âœ… Logging de tiempo de espera por peticiÃ³n

### 3. **ThrottledClient** (combinaciÃ³n de ambos)

Cliente completo que aplica **ambos lÃ­mites simultÃ¡neamente**:

```python
client = ThrottledClient(
    max_concurrent=10,      # MÃ¡ximo 10 peticiones simultÃ¡neas
    max_per_second=20       # MÃ¡ximo 20 peticiones por segundo
)

# Todas las operaciones CRUD respetan los lÃ­mites automÃ¡ticamente
productos = await client.listar_productos()
nuevo = await client.crear_producto(datos)
```

**Orden de aplicaciÃ³n**:
1. Primero: Rate limiting (espera por token)
2. Segundo: Concurrency limiting (espera por slot)
3. Finalmente: Ejecuta la peticiÃ³n

## ğŸ“Š DemostraciÃ³n

### Test Completo con VisualizaciÃ³n

```bash
python test_throttle_demo.py --test=full --num=50 --concurrent=10 --rate=20
```

**Genera**:
- ğŸ“ˆ GrÃ¡fica 1: Peticiones en vuelo vs tiempo (nunca excede lÃ­mite)
- ğŸ“Š GrÃ¡fica 2: Peticiones por segundo (respeta rate limit)
- â±ï¸ GrÃ¡fica 3: DuraciÃ³n y tiempo de espera por peticiÃ³n
- ğŸ“ Reporte detallado en consola

### ComparaciÃ³n Con/Sin Throttling

```bash
python test_throttle_demo.py --test=compare --num=50
```

**Muestra**:
- Tiempo total de ejecuciÃ³n
- Throughput efectivo
- NÃºmero de errores (sin throttling tÃ­picamente tiene mÃ¡s errores)
- VerificaciÃ³n de cumplimiento de lÃ­mites

## ğŸ” Ejemplo de Uso

```python
import asyncio
from throttle import ThrottledClient

async def main():
    # Configurar lÃ­mites
    async with ThrottledClient(
        max_concurrent=10,      # LÃ­mite de concurrencia
        max_per_second=20       # LÃ­mite de rate
    ) as client:
        
        # Crear 50 productos
        productos = []
        for i in range(50):
            producto = {
                "nombre": f"Producto {i}",
                "precio": 100 + i,
                "categoria": "test",
                "stock": 10
            }
            productos.append(producto)
        
        # Lanzar todas las tareas
        # Los limitadores se aplican automÃ¡ticamente
        tareas = [client.crear_producto(p) for p in productos]
        resultados = await asyncio.gather(*tareas)
        
        # Ver mÃ©tricas
        metrics = client.get_metrics()
        print(f"Total requests: {metrics['total_requests']}")
        print(f"Average wait time: {metrics['average_wait_time']:.3f}s")
        print(f"Max concurrent: {metrics['max_concurrent']}")

asyncio.run(main())
```

## ğŸ“ Estructura de Archivos

```
ACT5 AI/
â”œâ”€â”€ throttle.py                 # ğŸ”§ ImplementaciÃ³n principal
â”‚   â”œâ”€â”€ ConcurrencyLimiter      # Limita peticiones concurrentes
â”‚   â”œâ”€â”€ RateLimiter             # Limita peticiones por segundo
â”‚   â””â”€â”€ ThrottledClient         # Cliente completo con CRUD
â”‚
â”œâ”€â”€ test_throttle_demo.py       # ğŸ§ª Testing y demostraciÃ³n
â”‚   â”œâ”€â”€ ThrottleMonitor         # Captura mÃ©tricas en tiempo real
â”‚   â”œâ”€â”€ plot_metrics()          # Genera grÃ¡ficas matplotlib
â”‚   â””â”€â”€ ComparaciÃ³n tests       # Con/sin throttling
â”‚
â”œâ”€â”€ validadores.py              # âœ… ValidaciÃ³n de JSON (de ACT4)
â”œâ”€â”€ url_builder.py              # ğŸ”’ ConstrucciÃ³n segura de URLs (de ACT4)
â”œâ”€â”€ README.md                   # ğŸ“– Este archivo
â””â”€â”€ diagramas.md                # ğŸ“Š Diagramas temporales
```

## ğŸ¨ GrÃ¡ficas Generadas

El script de testing genera automÃ¡ticamente grÃ¡ficas con matplotlib:

### 1. Peticiones en Vuelo vs Tiempo
- Muestra cuÃ¡ntas peticiones estÃ¡n ejecutÃ¡ndose en cada momento
- LÃ­nea roja indica el lÃ­mite configurado
- Ãrea sombreada muestra el uso real
- **VerificaciÃ³n**: Nunca debe exceder la lÃ­nea roja

### 2. Peticiones por Segundo
- Histograma de peticiones agrupadas por segundo
- LÃ­nea roja indica el rate limit
- **VerificaciÃ³n**: Ninguna barra debe exceder la lÃ­nea roja

### 3. DuraciÃ³n y Tiempo de Espera
- Scatter plot de cada peticiÃ³n
- Naranja: DuraciÃ³n total
- Rojo: Tiempo de espera por rate limit
- Muestra distribuciÃ³n y promedio

## ğŸ§ª VerificaciÃ³n de LÃ­mites

El sistema verifica automÃ¡ticamente:

### âœ… LÃ­mite de Concurrencia
```
âœ… Concurrencia: 10/10 (RESPETADO)
```
**Criterio**: Nunca mÃ¡s de `max_concurrent` peticiones simultÃ¡neas

### âœ… LÃ­mite de Rate
```
âœ… Rate Limit: 20/20/s (RESPETADO)
```
**Criterio**: Nunca mÃ¡s de `max_per_second` peticiones en 1 segundo

### âŒ ViolaciÃ³n Detectada
```
âš ï¸ LÃMITE EXCEDIDO: 25 > 20
```
Si se detecta violaciÃ³n, se resalta en rojo en las grÃ¡ficas

## ğŸ“ Conceptos Clave

### Context Manager Pattern
```python
async with limiter.acquire():
    # El limitador garantiza:
    # 1. AdquisiciÃ³n antes de entrar
    # 2. LiberaciÃ³n al salir (incluso si hay excepciones)
    await hacer_peticion()
```

### Token Bucket Algorithm
```
Bucket: [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] (5 tokens)
         â†“
PeticiÃ³n 1: consume 1 token â†’ [ğŸª™ğŸª™ğŸª™ğŸª™_]
PeticiÃ³n 2: consume 1 token â†’ [ğŸª™ğŸª™ğŸª™__]
         â†“
DespuÃ©s de 1 segundo:
Regenera 5 tokens â†’ [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] (max 5)
```

### ComposiciÃ³n de Limitadores
```python
# Orden de aplicaciÃ³n:
async with rate_limiter.acquire():        # 1. Espera por token
    async with concurrency_limiter.acquire():  # 2. Espera por slot
        await hacer_peticion()             # 3. Ejecuta
```

## ğŸ“ˆ MÃ©tricas Capturadas

El `ThrottledClient` registra:

- `total_requests`: Total de peticiones hechas
- `successful_requests`: Peticiones exitosas
- `failed_requests`: Peticiones fallidas
- `in_flight`: Peticiones actualmente en ejecuciÃ³n
- `average_wait_time`: Tiempo promedio de espera por rate limit
- `total_bytes_sent`: Bytes enviados
- `total_bytes_received`: Bytes recibidos

Acceso a mÃ©tricas:
```python
metrics = client.get_metrics()
print(f"Throughput efectivo: {metrics['successful_requests'] / tiempo_total:.2f}/s")
```

## ğŸš€ Ventajas de Este DiseÃ±o

1. **âœ… Reutilizable**: Los limitadores son decoradores/context managers genÃ©ricos
2. **âœ… Composable**: Se pueden combinar mÃºltiples limitadores
3. **âœ… Observable**: Logging detallado y mÃ©tricas
4. **âœ… No-invasivo**: La lÃ³gica CRUD no cambia, el throttling es transparente
5. **âœ… Configurable**: LÃ­mites ajustables en runtime
6. **âœ… Resiliente**: Maneja excepciones correctamente

## ğŸ”§ ConfiguraciÃ³n Recomendada

Para el EcoMarket API:

```python
client = ThrottledClient(
    max_concurrent=10,      # No agotar file descriptors
    max_per_second=20       # Respetar rate limit del API
)
```

Para desarrollo/testing local:

```python
client = ThrottledClient(
    max_concurrent=5,       # Menos concurrencia
    max_per_second=10       # Rate mÃ¡s conservador
)
```

## ğŸ“š Referencias

- **asyncio.Semaphore**: [DocumentaciÃ³n Python](https://docs.python.org/3/library/asyncio-sync.html#asyncio.Semaphore)
- **Token Bucket Algorithm**: [Wikipedia](https://en.wikipedia.org/wiki/Token_bucket)
- **Context Managers**: [PEP 343](https://www.python.org/dev/peps/pep-0343/)

## ğŸ¯ ConclusiÃ³n

Este sistema de throttling:
- âœ… Previene sobrecarga del servidor
- âœ… Evita agotamiento de recursos del cliente
- âœ… Respeta rate limits del API
- âœ… Es reutilizable y extensible
- âœ… Incluye visualizaciÃ³n de mÃ©tricas
- âœ… Sigue patrones de diseÃ±o profesionales

**DiseÃ±ado como un ingeniero de control de trÃ¡fico profesional.** ğŸš¦
